1.Paper: Understanding the difficulty of training deep feedforward neural networks 
Blog: https://prateekvjoshi.com/2016/03/29/understanding-xavier-initialization-in-deep-neural-networks/
Summary: Weight can be initialized by Gaussion distribution with 1/n variance and n is the number of input dimension. This can keep the output and intput have the same variance.
